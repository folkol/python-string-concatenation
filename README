Microbenchmarks: Python String Concatenation

waymoot.org: Efficient String Concatenation in Python — An assessment of the performance of several methods

Introduction: Building long strings in the Python progamming language can sometimes result in very slow running code. In this article I investigate the computational performance of various string concatenation methods.

For this comparison I required a test problem that calls for the construction of very long strings out of a large number of segments. It should not do much other computation, so that the measured performance is dependent only on the string operation performance.

Aside: How determine the Sample Size?

loop_count = 20000
			ops/s	 	process size (kB)
Method 1	3770	 	2424
Method 2	2230	 	2424
Method 3	29,600	 	2452
Method 4	83,700	 	3028
Method 5	90,900	 	2536
Method 6	119,800	 	3000

loop_count = 500000
			ops/s	 	process size (kB)
Method 3	17,100	 	8,016
Method 4	74,800	 	22,872
Method 5	94,900	 	10,480
Method 6	102,100	 	22,844

Conclusions

Use method 6 in most real programs.


Efficient String Concatenation in Python (2016 edition)

Builds on top of the old article, with small changes due to the timing module not being available.


Method 1: simple concatenation: s1 += s2

Method 2: concatenation using MutableString (s1 += s2, where s1 is a MutableString)

Method 3: appending to a long array of char

Method 4: building a list of strings, then calling "".join()

Method 5: writing to a cStringIO buffer in memory using write()

Method 6: same as Method 4 but using a list comprehension inline

The results for Python 2.2.1 are below:

runtime (ms) 	concatenations per second 
Method 1 	55.11	362,910
Method 2 	74.67	267,852
Method 3 	10.80	1,851,337
Method 4 	6.21	3,220,611
Method 5 	8.11	2,467,612
Method 6 	5.42	3,694,808

So in Python 2.2.1 the list comprehension method was the fastest by a pretty clear margin. However when I re-ran using 2.7.12 things turned out very differently:

runtime (ms)	concatenations per second
Method 1	1.7995	11,113,977
Method 2	90.1073	221,957
Method 3	3.9557	5,055,967
Method 4	2.1804	9,172,689
Method 5	4.8047	4,162,585
Method 6	1.4191	14,093,289


+- Patch #980695:  Implements efficient string concatenation for statements
+  of the form s=s+t and s+=t.  This will vary across implementations.
+  Accordingly, the str.join() method is strongly preferred for performance
+  sensitive code.

commit 52a21b8e65e2a231595cfec639701266202438a2
Author: Raymond Hettinger <python@rcn.com>
Date:   Fri Aug 6 18:43:09 2004 +0000

    SF patch #980695:  efficient string concatenation
    (Original patch by Armin Rigo).

 virtual memory size

 http://fa.bianp.net/blog/2013/different-ways-to-get-memory-consumption-or-lessons-learned-from-memory_profiler/


On python 2.7.15 on docker for mac

(venv)master$ for i in {1..6}; do docker run --rm -v `pwd`/maclemon.py:/maclemon.py  python:2.7 python maclemon.py $i; done
method 1
time 6.27183914185 ms
output size  86 kb
process size 26640 kb

method 2
time 132.327079773 ms
output size  86 kb
process size 35656 kb

method 3
time 9.03797149658 ms
output size  86 kb
process size 28736 kb

method 4
time 6.8690776825 ms
output size  86 kb
process size 27688 kb

method 5
time 8.92305374146 ms
output size  86 kb
process size 26772 kb

method 6
time 6.41894340515 ms
output size  86 kb
process size 26920 kb


Move ps-subprocessess outside of the time measurement.

(venv)master$ for i in {1..6}; do docker run --rm -v `pwd`/maclemon.py:/maclemon.py  python:2.7 python maclemon.py $i; done
method 1
time 2.51483917236 ms
output size  86 kb
process size 26648 kb

method 2
time 128.169059753 ms
output size  86 kb
process size 35672 kb

method 3
time 4.55188751221 ms
output size  86 kb
process size 28936 kb

method 4
time 2.76112556458 ms
output size  86 kb
process size 26924 kb

method 5
time 8.16178321838 ms
output size  86 kb
process size 26648 kb

method 6
time 1.64890289307 ms
output size  86 kb
process size 26924 kb

Run 2:

(venv)master$ for i in {1..6}; do docker run --rm -v `pwd`/maclemon.py:/maclemon.py  python:2.7 python maclemon.py $i; done
method 1
time 4.97484207153 ms
output size  86 kb
process size  6372 kb

method 2
time 126.070022583 ms
output size  86 kb
process size  7192 kb

method 3
time 4.6820640564 ms
output size  86 kb
process size  6560 kb

method 4
time 3.37409973145 ms
output size  86 kb
process size  6700 kb

method 5
time 5.36012649536 ms
output size  86 kb
process size  6332 kb

method 6
time 1.78790092468 ms
output size  86 kb
process size  6836 kb


Python 2 on mac:

(venv)master$ for i in {1..6}; do python maclemon.py $i; done
method 1
time 2.14195251465 ms
output size  86 kb
process size   3744 kb

method 2
time 78.3200263977 ms
output size  86 kb
process size   5200 kb

method 3
time 6.11805915833 ms
output size  86 kb
process size   3720 kb

method 4
time 3.37505340576 ms
output size  86 kb
process size   4144 kb

method 5
time 6.92296028137 ms
output size  86 kb
process size   3940 kb

method 6
time 2.11215019226 ms
output size  86 kb
process size   4112 kb



Ran 2to3 on maclemon.py

Method 2 and 3 does not work in Python 3.

(venv) master$ for i in 1 4 5 6; do python maclemon.py $i; done
method 1
time 4.891872406005859 ms
output size  86.806640625 kb
process size   6888 kb

method 4
time 5.238056182861328 ms
output size  86.806640625 kb
process size   7456 kb

method 5
time 5.697011947631836 ms
output size  86.806640625 kb
process size   7284 kb

method 6
time 4.332065582275391 ms
output size  86.806640625 kb
process size   7396 kb



Pre-calculate the string segments.

method 1
time 1.9528865814208984 ms
output size  86.806640625 kb
process size   8460 kb

method 4
time 0.30422210693359375 ms
output size  86.806640625 kb
process size   8492 kb

method 5
time 2.2428035736083984 ms
output size  86.806640625 kb
process size   8592 kb

method 6
time 0.26607513427734375 ms
output size  86.806640625 kb
process size   8464 kb


(venv) master$ for i in 1 4 5 6; do python maclemon.py $i; done
method 1
time 1.9071102142333984 ms
output size  86.806640625 kb
process size   8556 kb

method 4
time 0.2818107604980469 ms
output size  86.806640625 kb
process size   8408 kb

method 5
time 2.0432472229003906 ms
output size  86.806640625 kb
process size   8544 kb

method 6
time 0.24390220642089844 ms
output size  86.806640625 kb
process size   8412 kb



Plot histogram of times, same graph.

plot how they scale with loop_count

Maybe area-chart where we plot max and min value?



Use timeit with number=1 and high repeat.



(venv) master$ for m in 1 4 5 6; do python maclemon.py $m 10; done
25.74896812438965
5.644083023071289
5.5999755859375
5.693197250366211
(venv) master$ sudo purge
(venv) master$ for m in 6 5 4 1; do python maclemon.py $m 10; done
31.599998474121094
5.453824996948242
5.334138870239258
6.019830703735352





Slides:

- Cover slide: "Python String Concatenation Performance Comparison (...or The Perils of Microbenchmarks!)"
    - a while ago, I pondered the performance characteristics of the different was to concatenate strings in Python — and decided to google it
- first page on google linked to an old article on waymoot.org
    - show screenshot
        - I tried each method of the methods as a separate test using it's own python process. 
        - I ran these tests using Python 2.2.1 on a 433MHz PII Celeron under FreeBSD 4.9.
    - waymoot's results
                        ms      ops/s       Process size (kB)
            Method 1    5300    3770	 	2424
            Method 2    8970    2230	 	2424
            Method 3    670     29,600	 	2452
            Method 4    240     83,700	 	3028
            Method 5    220     90,900	 	2536
            Method 6    170     119,800	 	3000

    - waymoot's conclusions
        Use method 6 in almost all real work scenarios.

- first page also included an article on mclemon, which built upon waymoot
    - maclemon's measurements – python 2.2

                    runtime (ms)	concatenations per second
        Method 1	55.11	        362,910
        Method 2	74.67	        221,957
        Method 3	10.80	        1,851,337
        Method 4	6.21	        3,220,611
        Method 5	8.11	        2,467,612
        Method 6	5.42	        3,694,808

    - maclemon's measurements – python 2.7

                    runtime (ms)    concatenations per second
        Method 1    1.7995           11,113,977
        Method 2    90.1073          221,957
        Method 3    3.9557           5,055,967
        Method 4    2.1804           9,172,689
        Method 5    4.8047           4,162,585
        Method 6    1.4191           14,093,289

    - maclemon's conclusions
        - They fixed method 1!
        - (Actually, they did optimize it – show commit)

- let's reproduce!
    - the code does not run on mac (due to incompatible ps...)
        - running in a virtual linux machine in the mac:
            root@ubuntu-xenial:/home/vagrant/Python-2.2.1# for m in {1..6}; do ./python /vagrant/mclemon_r0.py $m; done | sed -n '/method/{ N;N;N;N;s/\n//g;s/time/\t/;s/output size  86 kb//;s/process size/\t/p; }'
            method 1     98.0460643768 ms    19916 kb
            method 2     82.5369358063 ms    20016 kb
            method 3     24.0340232849 ms    22004 kb
            method 4     11.6310119629 ms    21320 kb
            method 5     11.5070343018 ms    20048 kb
            method 6     11.6939544678 ms    21320 kb

        - Yay! Seems to reproduce mclemon's findings!
        - try again, with reverse order
            root@ubuntu-xenial:/home/vagrant/Python-2.2.1# for m in {6..1}; do ./python /vagrant/mclemon_r0.py $m; done | sed -n '/method/{ N;N;N;N;s/\n//g;s/time/\t/;s/output size  86 kb//;s/process size/\t/p; }'
            method 6     88.8741016388 ms    21320 kb
            method 5     11.7211341858 ms    20048 kb
            method 4     12.9728317261 ms    21320 kb
            method 3     22.4149227142 ms    22004 kb
            method 2     84.0399265289 ms    20016 kb
            method 1     35.5710983276 ms    19916 kb
        - we will get back to why later.

    - timing module is removed in python2.7, run mclemon's updated version instead
    - run mclemon's code, as is.
        - does not work on mac os x
        - vagrant@ubuntu-xenial:~/Python-2.2.1$ for m in {1..6}; do ./python /vagrant/mclemon_r0.py $m; done | sed -n '/method/{ N;N;N;N;s/\n//g;s/time/\t/;s/output size  86 kb//;s/process size/\t/p; }'
            method 1     35.6409549713 ms    19916 kb
            method 2     89.5040035248 ms    20016 kb
            method 3     13.5838985443 ms    22004 kb
            method 4     11.8288993835 ms    21320 kb
            method 5     11.9268894196 ms    20048 kb
            method 6     10.8439922333 ms    21320 kb

        - python 2.7 in virtual machine
            vagrant@ubuntu-xenial:~$ for m in {1..6}; do python /vagrant/mclemon_r0.py $m; done | sed -n '/method/{ N;N;N;N;s/\n//g;s/time/\t/;s/output size  86 kb//;s/process size/\t/p; }'
            method 1     7.52997398376 ms    23620 kb
            method 2     86.6270065308 ms    23744 kb
            method 3     9.21201705933 ms    23620 kb
            method 4     7.69209861755 ms    24580 kb
            method 5     9.37390327454 ms    23772 kb
            method 6     7.57193565369 ms    23812 kb

        - on docker python:2.7
            (venv) $ for m in {1..6}; do docker run --rm -v `pwd`/mclemon_r0.py:/mclemon_r0.py python:2.7 python /mclemon_r0.py $m; done | sed -n '/method/{ N;N;N;N;s/\n//g;s/time/\t/;s/output size  86 kb//;s/process size/\t/p; }'
            method 1t 13.6058330536 mst 26640 kb
            method 2t 137.557983398 mst 35656 kb
            method 3t 11.442899704 mst 28736 kb
            method 4t 6.81900978088 mst 27688 kb
            method 5t 14.014005661 mst 26772 kb
            method 6t 7.49802589417 mst 26920 kb

        - on mac, with slight modification to ps
            (venv) $ for m in {1..6}; do python2.7 mclemon_r1.py $m; done | sed -n '/method/{ N;N;N;N;s/\n//g;s/time/\t/;s/output size  86 kb//;s/process size/\t/p; }'
            method 1t 7.2979927063 mst  4299280 kb
            method 2t 103.91998291 mst  4299424 kb
            method 3t 14.9240493774 mst  4299320 kb
            method 4t 16.4721012115 mst  4300364 kb
            method 5t 12.531042099 mst  4299408 kb
            method 6t 8.00180435181 mst  4299420 kb
            (venv) $ for m in {1..6}; do python2.7 mclemon_r1.py $m; done | sed -n '/method/{ N;N;N;N;s/\n//g;s/time/\t/;s/output size  86 kb//;s/process size/\t/p; }'
            method 1t 8.6829662323 mst  4299280 kb
            method 2t 94.1798686981 mst  4299424 kb
            method 3t 12.2678279877 mst  4299320 kb
            method 4t 112.466096878 mst  4300364 kb
            method 5t 11.2390518188 mst  4299408 kb
            method 6t 9.81187820435 mst  4299420 kb

        - Seems to very significantly in between runs
            - show histogram for one of them. note log scale

        - on mac, with ps_stats() moved outside of timing window
            - show histogram
            - show histogram for both r0 and r2

        - on mac, with repr outside of timing window
            - show histogram
            - show histogram for r0, r2 and r3

        - how to they scale?
            - (venv) $ for m in 1 3 4 5 6; do for i in {1..100}; do python2.7 mclemon_r4.py $m $(($i ** 2)) >>method$m.scale; done; done

        - convert to python 3
            - 2to3

        - skip this?
        - method 2 and 3 does not work in python 3
            - explanation?

        - (venv) $ for m in 1 4 5 6; do for i in {1..1000000..10000}; do python mclemon_r5.py $m $i; done >>method$m.scale; done
        - $ STEP=10000 python lines.py method{1,4,5,6}.scale

        - disable gc before testing
            - show histogram?

        - introduce the timeit module
            - complain about the high default number
            - mention gc.disable()
            - mention repeat

        - pypy
             $ for m in 1 4 6; do for i in {1..100000..1000}; do pypy mclemon_r6.py $m $i; done >>method$m.pypy; done
        - win



- outro
    - do not believe everything that you read on the internet
    - testing is hard
    - use str.join!




plot styles:
    fivethirtyeight
    ggplot
    seaborn-muted
    seaborn-pastel




method 1, 7.2979927063
method 2, 103.91998291
method 3, 14.9240493774
method 4, 16.4721012115
method 5, 12.531042099
method 6, 8.00180435181

method 1, 8.6829662323
method 2, 94.1798686981
method 3, 12.2678279877
method 4, 112.466096878
method 5, 11.2390518188
method 6, 9.81187820435












Draft:

- Cover slide:
    - Python String Concatenation Performance
    - ...or The Perils of Microbenchmarks (in scary font?)
- Some slide? Ponder gif?:
    - A while ago, I pondered the performance characteristics of str.join vs str.__iadd__ (”dunder i add, or in-place add.”). I decided to ask Google (big brother?) about it, and this talk is basically some blabbering about what I found.
    - (For those of you who are not programmers, ”string concatenation” is the act of constructing a new string by attaching — or concatenating — one string onto the end of another. Like "constructing "
    - ((And a string object is, in this context, a programmatic representation of a piece of text.))
    - The catch with this computation is that the Python representation of a string is an immutable object, which means that we risk, unless we are really careful. running into samething called ”quadraric behaviour” — which is programmerspeak for pain and suffering (etc?)
- Google.png:
    - On the first page of the search results, I found a link to an old article published on waymoot.com, as well as a more recent derivative of the same article published on mclemon in 2016.
- Waymoot.png:
    - The article on waymoot compared 6 different ways to concatenate 20.000 short strings (why this figure?), with a conclusion to use either str.join or by writing the text fragments to a pseudofile in cases where using str.join is inconvenient, both of which avoid the dreaded quadratic behaviour by using an intermediate — mutable — representation of the string.
    - test results

            Method 6,170
            Method 5,220
            Method 4,240
            Method 3,670
            Method 2,8970
            Method 1,5300

- Mclemon.png:
    - Fast-forward to 2016. Mclemon couldn’t reproduce waymoot’s findings. In particular, mclemon found (much) heigher performance on __iadd__.

        Method 6,    1.4191
        Method 5,    4.8047
        Method 4,    2.1804
        Method 3,    3.9557
        Method 2,    90.1073
        Method 1,    1.7995

    - test results
    - Mclemon tracked this down to a commit made by Raymond Hettinger back in 2004.
    commit 52a21b8e65e2a231595cfec639701266202438a2
    Author: Raymond Hettinger <python@rcn.com>
    Date:   Fri Aug 6 18:43:09 2004 +0000

        SF patch #980695:  efficient string concatenation
        (Original patch by Armin Rigo).

    diff --git a/Python/ceval.c b/Python/ceval.c
    index 6c457e125c..4dd31ab9ba 100644
    --- a/Python/ceval.c
    +++ b/Python/ceval.c
    @@ -85,6 +85,8 @@ static int exec_statement(PyFrameObject *,
    { HERE BE BLACK MAGICK }
    - Raymond is basically cheating, and actually mutating the old string object when it seems safe to do so — cheating quote?)

- (image of replicator?): waymoot and mclemon published their test programs, let's reproduce!
    - 

- show results for 20000 strings
    - is this a reasonable result?
- show result for 1000
    - is this a reasonable result?
- show result for 0 strings
    - is this a reasonable result?

- Let's look at the test methods
    - the original script does not work on mac, here are test results from a linux image
        - root@ubuntu-xenial:/home/vagrant/Python-2.2.1# for m in {1..6}; do ./python /vagrant/mclemon_r0.py $m; done | sed -n '/method/{ N;N;N;N;s/\n//g;s/time/\t/;s/output size  86 kb//;s/process size/\t/p; }'
            method 1     98.0460643768 ms    19916 kb
            method 2     82.5369358063 ms    20016 kb
            method 3     24.0340232849 ms    22004 kb
            method 4     11.6310119629 ms    21320 kb
            method 5     11.5070343018 ms    20048 kb
            method 6     11.6939544678 ms    21320 kb

            Method 6, 11.6939544678
            Method 5, 11.5070343018
            Method 4, 11.6310119629
            Method 3, 24.0340232849
            Method 2, 82.5369358063
            Method 1, 98.0460643768

    - Seems to match waymoot's results. Yay!
    - Right?
    - let's try running the tests in another order:
        - root@ubuntu-xenial:/home/vagrant/Python-2.2.1# for m in {6..1}; do ./python /vagrant/mclemon_r0.py $m; done | sed -n '/method/{ N;N;N;N;s/\n//g;s/time/\t/;s/output size  86 kb//;s/process size/\t/p; }'
            method 6     88.8741016388 ms    21320 kb
            method 5     11.7211341858 ms    20048 kb
            method 4     12.9728317261 ms    21320 kb
            method 3     22.4149227142 ms    22004 kb
            method 2     84.0399265289 ms    20016 kb
            method 1     35.5710983276 ms    19916 kb


            Method 6, 88.8741016388
            Method 5, 11.7211341858
            Method 4, 12.9728317261
            Method 3, 22.4149227142
            Method 2, 84.0399265289
            Method 1, 35.5710983276

        - Doh!
        - We will get back to why later.
    - Let's try a modern version of Python.
        - timing module is removed in python2.7, run mclemon's updated version instead.
        - vagrant@ubuntu-xenial:~/Python-2.2.1$ for m in {1..6}; do ./python /vagrant/mclemon_r0.py $m; done | sed -n '/method/{ N;N;N;N;s/\n//g;s/time/\t/;s/output size  86 kb//;s/process size/\t/p; }'
            method 1     35.6409549713 ms    19916 kb
            method 2     89.5040035248 ms    20016 kb
            method 3     13.5838985443 ms    22004 kb
            method 4     11.8288993835 ms    21320 kb
            method 5     11.9268894196 ms    20048 kb
            method 6     10.8439922333 ms    21320 kb
        - python 2.7 in virtual machine
            vagrant@ubuntu-xenial:~$ for m in {1..6}; do python /vagrant/mclemon_r0.py $m; done | sed -n '/method/{ N;N;N;N;s/\n//g;s/time/\t/;s/output size  86 kb//;s/process size/\t/p; }'
            method 1     7.52997398376 ms    23620 kb
            method 2     86.6270065308 ms    23744 kb
            method 3     9.21201705933 ms    23620 kb
            method 4     7.69209861755 ms    24580 kb
            method 5     9.37390327454 ms    23772 kb
            method 6     7.57193565369 ms    23812 kb


            Method 6, 7.57193565369
            Method 5, 9.37390327454
            Method 4, 7.69209861755
            Method 3, 9.21201705933
            Method 2, 86.6270065308
            Method 1, 7.52997398376

        - seems to reproduce mclemon's results
        - run the exact same test again
        -  (venv) $ for m in {1..6}; do python2.7 mclemon_r1.py $m; done | sed -n '/method/{ N;N;N;N;s/\n//g;s/time/\t/;s/output size  86 kb//;s/process size/\t/p; }'
            method 1t 7.2979927063 mst  4299280 kb
            method 2t 103.91998291 mst  4299424 kb
            method 3t 14.9240493774 mst  4299320 kb
            method 4t 16.4721012115 mst  4300364 kb
            method 5t 12.531042099 mst  4299408 kb
            method 6t 8.00180435181 mst  4299420 kb
            (venv) $ for m in {1..6}; do python2.7 mclemon_r1.py $m; done | sed -n '/method/{ N;N;N;N;s/\n//g;s/time/\t/;s/output size  86 kb//;s/process size/\t/p; }'
            method 1t 8.6829662323 mst  4299280 kb
            method 2t 94.1798686981 mst  4299424 kb
            method 3t 12.2678279877 mst  4299320 kb
            method 4t 112.466096878 mst  4300364 kb
            method 5t 11.2390518188 mst  4299408 kb
            method 6t 9.81187820435 mst  4299420 kb


            Method 6, 9.81187820435
            Method 5, 11.2390518188
            Method 4, 112.466096878
            Method 3, 12.2678279877
            Method 2, 94.1798686981
            Method 1, 8.6829662323

        - The results seems to very a lot....
        - Seems to very significantly in between runs
            - show histogram for one of them. note log scale
            - show histogram for all of them.
        - Let's take a look at what the test results are actually doing
            - The test is producing and concatenating strings, and then spawning a sub process to measure memory usage...
        - I wonder if scanning $PATH, and potentially loading the ps binary from disk, will affect the "concatenation times" in any way?
        - Let's re-run the tests with ps_stats moved out of the measurement window
            - show new histograms. Maybe in same graph as the old ones? 
        - What if constructing strings from numbers isn't free?
            - show new histograms, with the repr-part moved outside of the measuring windows.
            - show new and old
        - Enter the timeit module
            - The tests above can be done with the timeit module:
                >>> from timeit import timeit
                >>> timeit("''.join(ss)", "ss = [repr(n) for n in range(20_000)")
                423 years
            - Wat?
            - timeit, by default, runs the statement 1_000_000 times!
                - This takes ages for non-trivial snippets – but it also obscures the distribution of results
                >>> timeit("''.join(ss)", "ss = [repr(n) for n in range(20000)]", number=1)
                0.00043858299613930285
            - there is also a repeat-function in the timeit module, that just runs timeit a number of times and returns a list of results
                >>> repeat("''.join(ss)", "ss = [repr(n) for n in range(20000)]", number=1, repeat=1000)
                ...
                - show histogram
        - Armed with the timeit module, we can do some more testing.
        - Scale

- conclusion
    - do not trust everthing that you read on the internet
    - testing is hard
    - use str.join!
    (- thank you)

